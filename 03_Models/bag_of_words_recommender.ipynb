{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple bag of word type reccomenders\n",
    "\n",
    "So far we have a reccomender using a term-frequency matrix. Each \"document\" (titles or abstracts) of a news article gets a vector\n",
    "with the count of the unique words found in the document collection.\n",
    "Then, a similarity matrix is calculated (cosine similarity for now). We can select an article and look in the similarity matrix to find the top n most similar articles\n",
    "\n",
    "\n",
    "#### Things to do\n",
    "- look at other matrix representations\n",
    "    - Simple binary representation (only 1 if term in document, 0 otherwise)\n",
    "    - TF-IDF matrix (terms that are less frequent in the collection are weighted more)\n",
    "\n",
    "- look at other similarity measures\n",
    "    - cosine similarity is often most popular, but others can be explored\n",
    "\n",
    "- combine title and abstract columns and do the techniques on those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsId                  0\n",
      "category                0\n",
      "subcategory             0\n",
      "title                   0\n",
      "abstract             2666\n",
      "url                     0\n",
      "title_entities          3\n",
      "abstract_entities       4\n",
      "dtype: int64\n",
      "we see that we are missing 2666 abstracts. We need to drop these when we use the abstracts \n",
      "\n",
      "impressionId        0\n",
      "userId              0\n",
      "timestamp           0\n",
      "click_history    3238\n",
      "impressions         0\n",
      "dtype: int64\n",
      "we see that we are missing 3238 click histories. We need to drop these rows\n",
      "impressionId     0\n",
      "userId           0\n",
      "timestamp        0\n",
      "click_history    0\n",
      "impressions      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "news_data = pd.read_csv(\"../MINDsmall_train/news.tsv\",\n",
    "    sep='\\t',\n",
    "    names=[\"newsId\", \"category\", \"subcategory\", \"title\",\"abstract\", \"url\", \"title_entities\",\"abstract_entities\"]\n",
    ")\n",
    "\n",
    "behaviors_data = pd.read_csv(\n",
    "    \"../MINDsmall_train/behaviors.tsv\",\n",
    "    sep='\\t',\n",
    "    names=[\"impressionId\", \"userId\", \"timestamp\", \"click_history\", \"impressions\"],\n",
    "    parse_dates=['timestamp'] \n",
    ")\n",
    "\n",
    "#Pre-processing\n",
    "\n",
    "# check for missing values\n",
    "print(news_data.isna().sum())\n",
    "print(\"we see that we are missing 2666 abstracts. We need to drop these when we use the abstracts \\n\")\n",
    "\n",
    "\n",
    "# check for missing values\n",
    "print(behaviors_data.isna().sum())\n",
    "print(\"we see that we are missing 3238 click histories. We need to drop these rows\")\n",
    "\n",
    "# remove null values\n",
    "news_data = news_data.dropna().reset_index(drop=True)\n",
    "behaviors_data = behaviors_data.dropna().reset_index(drop=True)\n",
    "print(behaviors_data.isna().sum())\n",
    "\n",
    "\n",
    "behaviors_data['timestamp'] = pd.to_datetime(behaviors_data['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "behaviors_data['impressions_list'] = behaviors_data['impressions'].str.split()\n",
    "\n",
    "\n",
    "# behaviors_data['hour_of_day'] = behaviors_data['timestamp'].dt.hour\n",
    "# behaviors_data['clicks'] = behaviors_data['click_history'].str.split().str.len()\n",
    "# behaviors_data['impressions_count'] = behaviors_data['impressions_list'].str.len()\n",
    "\n",
    "# sort behaviors_data by timestamp\n",
    "behaviors_data = behaviors_data.sort_values(by='timestamp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressionId</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>click_history</th>\n",
       "      <th>impressions</th>\n",
       "      <th>impressions_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19705</th>\n",
       "      <td>20112</td>\n",
       "      <td>U65916</td>\n",
       "      <td>2019-11-09 00:00:19</td>\n",
       "      <td>N51706 N40767 N12096 N9798 N38802 N54827 N5780...</td>\n",
       "      <td>N54300-0 N46057-1 N57005-0 N52154-0 N57099-0 N...</td>\n",
       "      <td>[N54300-0, N46057-1, N57005-0, N52154-0, N5709...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13531</th>\n",
       "      <td>13807</td>\n",
       "      <td>U49985</td>\n",
       "      <td>2019-11-09 00:01:13</td>\n",
       "      <td>N5056 N29975 N53234 N39603 N50032 N8422 N53580...</td>\n",
       "      <td>N20602-0 N50059-0 N57768-1 N50135-1 N15134-0 N...</td>\n",
       "      <td>[N20602-0, N50059-0, N57768-1, N50135-1, N1513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27115</th>\n",
       "      <td>27660</td>\n",
       "      <td>U25550</td>\n",
       "      <td>2019-11-09 00:02:44</td>\n",
       "      <td>N17260 N38298 N33976 N47719 N14888 N18870 N4607</td>\n",
       "      <td>N50135-0 N15134-0 N52433-1 N20602-0 N64536-0</td>\n",
       "      <td>[N50135-0, N15134-0, N52433-1, N20602-0, N6453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149080</th>\n",
       "      <td>152217</td>\n",
       "      <td>U19710</td>\n",
       "      <td>2019-11-09 00:02:50</td>\n",
       "      <td>N3530 N48284 N43019 N62546 N138 N13138 N10676 ...</td>\n",
       "      <td>N57099-0 N30295-0 N21086-0 N5379-0 N57005-0 N4...</td>\n",
       "      <td>[N57099-0, N30295-0, N21086-0, N5379-0, N57005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41348</th>\n",
       "      <td>42166</td>\n",
       "      <td>U38106</td>\n",
       "      <td>2019-11-09 00:03:09</td>\n",
       "      <td>N16874 N264 N48697 N51366</td>\n",
       "      <td>N3491-0 N20602-0 N25785-0 N23575-0 N38783-0 N1...</td>\n",
       "      <td>[N3491-0, N20602-0, N25785-0, N23575-0, N38783...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        impressionId  userId           timestamp  \\\n",
       "19705          20112  U65916 2019-11-09 00:00:19   \n",
       "13531          13807  U49985 2019-11-09 00:01:13   \n",
       "27115          27660  U25550 2019-11-09 00:02:44   \n",
       "149080        152217  U19710 2019-11-09 00:02:50   \n",
       "41348          42166  U38106 2019-11-09 00:03:09   \n",
       "\n",
       "                                            click_history  \\\n",
       "19705   N51706 N40767 N12096 N9798 N38802 N54827 N5780...   \n",
       "13531   N5056 N29975 N53234 N39603 N50032 N8422 N53580...   \n",
       "27115     N17260 N38298 N33976 N47719 N14888 N18870 N4607   \n",
       "149080  N3530 N48284 N43019 N62546 N138 N13138 N10676 ...   \n",
       "41348                           N16874 N264 N48697 N51366   \n",
       "\n",
       "                                              impressions  \\\n",
       "19705   N54300-0 N46057-1 N57005-0 N52154-0 N57099-0 N...   \n",
       "13531   N20602-0 N50059-0 N57768-1 N50135-1 N15134-0 N...   \n",
       "27115        N50135-0 N15134-0 N52433-1 N20602-0 N64536-0   \n",
       "149080  N57099-0 N30295-0 N21086-0 N5379-0 N57005-0 N4...   \n",
       "41348   N3491-0 N20602-0 N25785-0 N23575-0 N38783-0 N1...   \n",
       "\n",
       "                                         impressions_list  \n",
       "19705   [N54300-0, N46057-1, N57005-0, N52154-0, N5709...  \n",
       "13531   [N20602-0, N50059-0, N57768-1, N50135-1, N1513...  \n",
       "27115   [N50135-0, N15134-0, N52433-1, N20602-0, N6453...  \n",
       "149080  [N57099-0, N30295-0, N21086-0, N5379-0, N57005...  \n",
       "41348   [N3491-0, N20602-0, N25785-0, N23575-0, N38783...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get news data from df of behaviours (training data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressionId</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>click_history</th>\n",
       "      <th>impressions</th>\n",
       "      <th>impressions_list</th>\n",
       "      <th>last_clicked_article</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20112</td>\n",
       "      <td>U65916</td>\n",
       "      <td>2019-11-09 00:00:19</td>\n",
       "      <td>N51706 N40767 N12096 N9798 N38802 N54827 N5780...</td>\n",
       "      <td>N54300-0 N46057-1 N57005-0 N52154-0 N57099-0 N...</td>\n",
       "      <td>[N54300-0, N46057-1, N57005-0, N52154-0, N5709...</td>\n",
       "      <td>N2678</td>\n",
       "      <td>'The bridge has definitely been burned': Willi...</td>\n",
       "      <td>Seven-time Pro Bowl left tackle Trent Williams...</td>\n",
       "      <td>'The bridge has definitely been burned': Willi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13807</td>\n",
       "      <td>U49985</td>\n",
       "      <td>2019-11-09 00:01:13</td>\n",
       "      <td>N5056 N29975 N53234 N39603 N50032 N8422 N53580...</td>\n",
       "      <td>N20602-0 N50059-0 N57768-1 N50135-1 N15134-0 N...</td>\n",
       "      <td>[N20602-0, N50059-0, N57768-1, N50135-1, N1513...</td>\n",
       "      <td>N61880</td>\n",
       "      <td>Dean Martin's Daughter Speaks Out About John L...</td>\n",
       "      <td>Dean Martin's Daughter on New 'Baby, It's Cold...</td>\n",
       "      <td>Dean Martin's Daughter Speaks Out About John L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27660</td>\n",
       "      <td>U25550</td>\n",
       "      <td>2019-11-09 00:02:44</td>\n",
       "      <td>N17260 N38298 N33976 N47719 N14888 N18870 N4607</td>\n",
       "      <td>N50135-0 N15134-0 N52433-1 N20602-0 N64536-0</td>\n",
       "      <td>[N50135-0, N15134-0, N52433-1, N20602-0, N6453...</td>\n",
       "      <td>N4607</td>\n",
       "      <td>Cause determined in Jessi Combs' fatal speed r...</td>\n",
       "      <td>Occurred at speeds near 550 mph</td>\n",
       "      <td>Cause determined in Jessi Combs' fatal speed r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152217</td>\n",
       "      <td>U19710</td>\n",
       "      <td>2019-11-09 00:02:50</td>\n",
       "      <td>N3530 N48284 N43019 N62546 N138 N13138 N10676 ...</td>\n",
       "      <td>N57099-0 N30295-0 N21086-0 N5379-0 N57005-0 N4...</td>\n",
       "      <td>[N57099-0, N30295-0, N21086-0, N5379-0, N57005...</td>\n",
       "      <td>N41244</td>\n",
       "      <td>Keanu Reeves holds hands with Alexandra Grant ...</td>\n",
       "      <td>The Internet is even more in love with Keanu R...</td>\n",
       "      <td>Keanu Reeves holds hands with Alexandra Grant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42166</td>\n",
       "      <td>U38106</td>\n",
       "      <td>2019-11-09 00:03:09</td>\n",
       "      <td>N16874 N264 N48697 N51366</td>\n",
       "      <td>N3491-0 N20602-0 N25785-0 N23575-0 N38783-0 N1...</td>\n",
       "      <td>[N3491-0, N20602-0, N25785-0, N23575-0, N38783...</td>\n",
       "      <td>N51366</td>\n",
       "      <td>See massive bear stuck in Lake Tahoe dumpster ...</td>\n",
       "      <td>Placer County Sheriff's deputies encounter so ...</td>\n",
       "      <td>See massive bear stuck in Lake Tahoe dumpster ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressionId  userId           timestamp  \\\n",
       "0         20112  U65916 2019-11-09 00:00:19   \n",
       "1         13807  U49985 2019-11-09 00:01:13   \n",
       "2         27660  U25550 2019-11-09 00:02:44   \n",
       "3        152217  U19710 2019-11-09 00:02:50   \n",
       "4         42166  U38106 2019-11-09 00:03:09   \n",
       "\n",
       "                                       click_history  \\\n",
       "0  N51706 N40767 N12096 N9798 N38802 N54827 N5780...   \n",
       "1  N5056 N29975 N53234 N39603 N50032 N8422 N53580...   \n",
       "2    N17260 N38298 N33976 N47719 N14888 N18870 N4607   \n",
       "3  N3530 N48284 N43019 N62546 N138 N13138 N10676 ...   \n",
       "4                          N16874 N264 N48697 N51366   \n",
       "\n",
       "                                         impressions  \\\n",
       "0  N54300-0 N46057-1 N57005-0 N52154-0 N57099-0 N...   \n",
       "1  N20602-0 N50059-0 N57768-1 N50135-1 N15134-0 N...   \n",
       "2       N50135-0 N15134-0 N52433-1 N20602-0 N64536-0   \n",
       "3  N57099-0 N30295-0 N21086-0 N5379-0 N57005-0 N4...   \n",
       "4  N3491-0 N20602-0 N25785-0 N23575-0 N38783-0 N1...   \n",
       "\n",
       "                                    impressions_list last_clicked_article  \\\n",
       "0  [N54300-0, N46057-1, N57005-0, N52154-0, N5709...                N2678   \n",
       "1  [N20602-0, N50059-0, N57768-1, N50135-1, N1513...               N61880   \n",
       "2  [N50135-0, N15134-0, N52433-1, N20602-0, N6453...                N4607   \n",
       "3  [N57099-0, N30295-0, N21086-0, N5379-0, N57005...               N41244   \n",
       "4  [N3491-0, N20602-0, N25785-0, N23575-0, N38783...               N51366   \n",
       "\n",
       "                                               title  \\\n",
       "0  'The bridge has definitely been burned': Willi...   \n",
       "1  Dean Martin's Daughter Speaks Out About John L...   \n",
       "2  Cause determined in Jessi Combs' fatal speed r...   \n",
       "3  Keanu Reeves holds hands with Alexandra Grant ...   \n",
       "4  See massive bear stuck in Lake Tahoe dumpster ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Seven-time Pro Bowl left tackle Trent Williams...   \n",
       "1  Dean Martin's Daughter on New 'Baby, It's Cold...   \n",
       "2                    Occurred at speeds near 550 mph   \n",
       "3  The Internet is even more in love with Keanu R...   \n",
       "4  Placer County Sheriff's deputies encounter so ...   \n",
       "\n",
       "                                            combined  \n",
       "0  'The bridge has definitely been burned': Willi...  \n",
       "1  Dean Martin's Daughter Speaks Out About John L...  \n",
       "2  Cause determined in Jessi Combs' fatal speed r...  \n",
       "3  Keanu Reeves holds hands with Alexandra Grant ...  \n",
       "4  See massive bear stuck in Lake Tahoe dumpster ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "behaviors_data.head()\n",
    "behaviors_data['last_clicked_article'] = behaviors_data['click_history'].str.split().str[-1]\n",
    "\n",
    "# join the training data with the news data to access all info about news article in \"last_clicked_article\"\n",
    "behaviors_data = behaviors_data.join(news_data.set_index('newsId')[[\"title\", \"abstract\"]], on='last_clicked_article')\n",
    "\n",
    "#combination column\n",
    "behaviors_data['combined'] = behaviors_data['title'] + \" \" + behaviors_data['abstract']\n",
    "\n",
    "\n",
    "\n",
    "behaviors_data.isna().sum() # there were somehow 40 missing values in the title and abstract columns. We need to drop these rows\n",
    "behaviors_data = behaviors_data.dropna().reset_index(drop=True)\n",
    "behaviors_data.head()\n",
    "\n",
    "\n",
    "behaviors_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating matrix representations for the titles and abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feature must be \"title\", \"abstract\" or \"combined\"\n",
    "def create_matrix(data, feature = \"title\"):\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    tf_matrix = vectorizer.fit_transform(data[feature])\n",
    "    return tf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity matrix\n",
    "def create_similarity_matrix(tf_matrix):\n",
    "    similarity_matrix = cosine_similarity(tf_matrix)\n",
    "    return similarity_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation function\n",
    "Takes in an article_id, and finds the top_n most similar items by using the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47675"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = news_data['newsId' == \"N2678\"].index[0]\n",
    "idx = news_data[news_data['newsId'] == \"N2678\"].index[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_articles(training_df, evaluation_row, similarity_matrix, top_n=5):\n",
    "\n",
    "    article_id = evaluation_row['click_history'].split()[-1]\n",
    "\n",
    "    # Get the index of the article\n",
    "    idx = training_df['newsId' == article_id].index[0]\n",
    "    idx = df[df['newsId'] == article_id].index[0]\n",
    "\n",
    "    \n",
    "    # Get the similarity scores\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    \n",
    "    # Sort the articles based on the similarity scores\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the indices of the top_n most similar articles\n",
    "    top_article_indices = [i[0] for i in similarity_scores[1:top_n+1]]\n",
    "    \n",
    "    # Return the top_n most similar articles\n",
    "    return df[['newsId']].iloc[top_article_indices]\n",
    "\n",
    "# Example: Recommend articles similar to the first article in the dataset\n",
    "recommended_articles = recommend_articles(\"N55528\", title_similarity_matrix, top_n=5)\n",
    "print(recommended_articles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "start time  2019-11-09 00:00:19\n",
      "end time  2019-11-09 06:00:19\n",
      "0 days 03:00:00\n",
      "max time  2019-11-09 16:32:50\n",
      "Start time: 2019-11-09 00:00:19, End time: 2019-11-09 06:00:19\n",
      "Shape of evaluation data (2902, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "recommend_articles() missing 1 required positional argument: 'similarity_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m evaluation_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     43\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     clicked_article \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((n\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpressions_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m n\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clicked_article \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "\u001b[1;31mTypeError\u001b[0m: recommend_articles() missing 1 required positional argument: 'similarity_matrix'"
     ]
    }
   ],
   "source": [
    "INITIAL_WINDOW_SIZE = 6\n",
    "MAX_WINDOW_SIZE = 72\n",
    "SLIDE_SIZE = 3\n",
    "FEATURE = \"title\"\n",
    "behaviors_data = behaviors_data.head(10000)\n",
    "hits_per_window = {} #key = (start_time, end_time), value = (hits, total_rows)\n",
    "#smaller behaviors_data \n",
    "\n",
    "\n",
    "start_time = behaviors_data['timestamp'].min()\n",
    "end_time = start_time + pd.Timedelta(hours=INITIAL_WINDOW_SIZE)\n",
    "\n",
    "\n",
    "def get_data_split(start_time, end_time, test_window_size=SLIDE_SIZE):\n",
    "    # returns a training and evaluation split\n",
    "    training_data = behaviors_data[(behaviors_data['timestamp'] >= start_time) & (behaviors_data['timestamp'] < end_time)]\n",
    "    evaluation_data = behaviors_data[(behaviors_data['timestamp'] >= end_time) & (behaviors_data['timestamp'] < end_time + pd.Timedelta(hours=test_window_size))]\n",
    "    return training_data, evaluation_data\n",
    "\n",
    "\n",
    "\n",
    "print(\"TEST\")\n",
    "print(\"start time \" , start_time)\n",
    "print(\"end time \" , end_time)\n",
    "print(pd.Timedelta(hours=SLIDE_SIZE))\n",
    "print(\"max time \" , behaviors_data['timestamp'].max())\n",
    "      \n",
    "\n",
    "#The sliding window\n",
    "while end_time + pd.Timedelta(hours=SLIDE_SIZE) <= behaviors_data['timestamp'].max():\n",
    "    print(f\"Start time: {start_time}, End time: {end_time}\")\n",
    "    training_data, evaluation_data = get_data_split(start_time, end_time)\n",
    "\n",
    "    tf_matrix = create_matrix(training_data, FEATURE)\n",
    "    similarity_matrix = create_similarity_matrix(tf_matrix)\n",
    "    \n",
    "    #recommend for the rows in the evaluation data based on the similiarity matrix we created with the training data\n",
    "    #evaluate the hit rate based on the recommendations and the impressions in the evaluation row\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    print(f'Shape of evaluation data {evaluation_data.shape}')\n",
    "    for index, row in evaluation_data.iterrows():\n",
    "        total += 1\n",
    "\n",
    "        recommendations = recommend_articles(training_data, row, similarity_matrix, top_n=5)\n",
    "        clicked_article = next((n.split(\"-\")[0] for n in row['impressions_list'] if n.split(\"-\")[1] == \"1\"), None)\n",
    "\n",
    "        if clicked_article in recommendations:\n",
    "            hits += 1\n",
    "            print(f'Hit for user {index} with article {clicked_article} and recommendations {recommendations}')\n",
    "\n",
    "        print(f'Recommendations for user {index}: {recommendations}')\n",
    "        print(f'Actual click for user {index}: {clicked_article}')\n",
    "    hits_per_window[(start_time, end_time)] = (hits, total)\n",
    "\n",
    "    print(f\"Start time: {start_time}, End time: {end_time}\")\n",
    "    end_time += pd.Timedelta(hours=SLIDE_SIZE)\n",
    "    if (end_time - start_time) > pd.Timedelta(hours = MAX_WINDOW_SIZE):\n",
    "        print(\"\\n\")\n",
    "        print(\"Increasing start time\")\n",
    "        print(\"\\n\")\n",
    "        #remove data from the beginning of the training data\n",
    "        start_time += pd.Timedelta(hours=SLIDE_SIZE)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
